{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4de0e939",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15736/240669733.py:20: DeprecationWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if ptypes.is_datetime64tz_dtype(df[ds_col]):\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def copy_last_n_days_with_date_shift(\n",
    "    csv_path: str,\n",
    "    source_station: str,\n",
    "    target_station: str,\n",
    "    desired_last_date: str = \"2025-11-03\",   # can be \"YYYY-MM-DD\" or \"YYYY-MM-DD HH:MM:SS\"\n",
    "    window_days: int = 30,\n",
    "    out_path: str = \"data_with_copied_station.csv\",\n",
    "    ds_col: str = \"ds\",\n",
    "    station_col: str = \"station\",\n",
    "    tz: str = \"Asia/Bangkok\",\n",
    "):\n",
    "    # 1. load and parse timestamps\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df[ds_col] = pd.to_datetime(df[ds_col], errors=\"raise\")\n",
    "\n",
    "    # 2. ensure timestamps are tz-aware in Bangkok\n",
    "    import pandas.api.types as ptypes\n",
    "    if ptypes.is_datetime64tz_dtype(df[ds_col]):\n",
    "        df[ds_col] = df[ds_col].dt.tz_convert(tz)\n",
    "    else:\n",
    "        df[ds_col] = df[ds_col].dt.tz_localize(tz)\n",
    "\n",
    "    # 3. get source station data and its last timestamp\n",
    "    src = df[df[station_col] == source_station].sort_values(by=ds_col)\n",
    "    if src.empty:\n",
    "        raise ValueError(f\"No rows found for source station '{source_station}'\")\n",
    "\n",
    "    src_last = src[ds_col].max()\n",
    "\n",
    "    # 4. pick the last `window_days` (rows within last window_days period up to src_last)\n",
    "    cutoff = src_last - pd.Timedelta(days=window_days - 1)  # inclusive window\n",
    "    src_window = src[src[ds_col] >= cutoff].copy()\n",
    "    if src_window.empty:\n",
    "        raise ValueError(\"No rows found in the requested window. \"\n",
    "                         \"You may want to use fewer days or check the source data.\")\n",
    "\n",
    "    # 5. build desired_last\n",
    "    # If user provided a time in the string (e.g. \"2025-11-03 15:30:00\"), use that exact datetime.\n",
    "    # If user provided only a date (\"2025-11-03\"), preserve the time-of-day from src_last.\n",
    "    user_str = str(desired_last_date)\n",
    "    has_time = \":\" in user_str  # simple heuristic: if there's a colon, the user included time\n",
    "\n",
    "    parsed = pd.to_datetime(desired_last_date)  # may be tz-naive\n",
    "    if has_time:\n",
    "        # Use the provided date+time (then localize/convert to tz)\n",
    "        desired_last = pd.Timestamp(parsed)\n",
    "        # make tz-aware in Bangkok\n",
    "        if desired_last.tzinfo is None:\n",
    "            desired_last = desired_last.tz_localize(tz)\n",
    "        else:\n",
    "            desired_last = desired_last.tz_convert(tz)\n",
    "    else:\n",
    "        # Only a date provided -> preserve time-of-day from src_last\n",
    "        desired_base = pd.Timestamp(parsed.date(), tz=tz)  # midnight at that date in tz\n",
    "        desired_last = desired_base.replace(\n",
    "            hour=src_last.hour,\n",
    "            minute=src_last.minute,\n",
    "            second=src_last.second,\n",
    "            microsecond=src_last.microsecond\n",
    "        )\n",
    "\n",
    "    # 6. compute shift and apply to the selected window\n",
    "    delta = desired_last - src_last\n",
    "    src_window[ds_col] = src_window[ds_col] + delta\n",
    "\n",
    "    # 7. set station to target and (optionally) change any other id fields if needed\n",
    "    src_window[station_col] = target_station\n",
    "\n",
    "    # 8. append to original df (or you can write src_window separately)\n",
    "    df_out = pd.concat([df, src_window], ignore_index=True)\n",
    "\n",
    "    # optional: sort by station then time (or any other desired sort)\n",
    "    df_out.sort_values(by=[station_col, ds_col], inplace=True, ignore_index=True)\n",
    "\n",
    "    # 9. save result\n",
    "    df_out.to_csv(out_path, index=False, date_format=\"%Y-%m-%d %H:%M:%S%z\")\n",
    "\n",
    "    return df_out, src_window\n",
    "\n",
    "# -------------------------\n",
    "# Example usage to make the last copied timestamp = 2025-11-03 15:30:00+07:00:\n",
    "df_full, new_rows = copy_last_n_days_with_date_shift(\n",
    "    csv_path=\"/workspaces/Baswap-app/dataset/merged_all_data copy.csv\",\n",
    "    source_station=\"CanGio\",\n",
    "    target_station=\"VGU\",\n",
    "    desired_last_date=\"2025-11-04 15:30:00\",\n",
    "    window_days=30,\n",
    "    out_path=\"/workspaces/Baswap-app/dataset/merged_all_data copy.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b79d093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed file to: /workspaces/Baswap-app/dataset/merged_all_data_new.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# adjust path/name\n",
    "infile = \"/workspaces/Baswap-app/dataset/merged_all_data.csv\"\n",
    "outfile = \"/workspaces/Baswap-app/dataset/merged_all_data_new.csv\"\n",
    "\n",
    "# read CSV\n",
    "df = pd.read_csv(infile)\n",
    "\n",
    "# drop Unnamed: 0 if it's just an index column\n",
    "if \"Unnamed: 0\" in df.columns:\n",
    "    # only drop if it looks like a default index column (all integers or monotonic)\n",
    "    try:\n",
    "        if pd.api.types.is_integer_dtype(df[\"Unnamed: 0\"]) or df[\"Unnamed: 0\"].is_monotonic_increasing:\n",
    "            df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "    except Exception:\n",
    "        # if any problem, still safe to drop if user expects it\n",
    "        df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "# find EC column (exact match first, else fuzzy)\n",
    "ec_original = \"EC[g/l]\"\n",
    "\n",
    "# coerce EC column to numeric (non-numeric -> NaN)\n",
    "df[ec_original] = pd.to_numeric(df[ec_original], errors=\"coerce\")\n",
    "\n",
    "# keep only ds, station and EC\n",
    "keep_cols = [\"ds\", \"station\", ec_original]\n",
    "missing = [c for c in keep_cols if c not in df.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"Missing required column(s): {missing}\")\n",
    "\n",
    "df = df[keep_cols].copy()\n",
    "\n",
    "# optional: parse ds to datetime (uncomment if you want)\n",
    "# df[\"ds\"] = pd.to_datetime(df[\"ds\"], errors=\"coerce\")\n",
    "\n",
    "# rename EC column\n",
    "df = df.rename(columns={ec_original: \"EC Value (g/l)\"})\n",
    "\n",
    "# compute EC Value (us/cm)\n",
    "# multiplier is 2000 per your instruction\n",
    "df[\"EC Value (us/cm)\"] = df[\"EC Value (g/l)\"] * 2000\n",
    "\n",
    "# (optional) reorder columns\n",
    "df = df[[\"ds\", \"station\", \"EC Value (g/l)\", \"EC Value (us/cm)\"]]\n",
    "\n",
    "# save\n",
    "df.to_csv(outfile, index=False)\n",
    "\n",
    "print(f\"Saved processed file to: {outfile}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5756d2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 03:59:05.904 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-11-03 03:59:05.906 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-03 03:59:06.246 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /home/vscode/.local/lib/python3.11/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-11-03 03:59:06.246 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-03 03:59:06.247 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-03 03:59:06.248 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-03 03:59:06.758 Thread 'Thread-12': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-03 03:59:06.760 Thread 'Thread-12': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-03 03:59:06.766 Thread 'Thread-12': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-03 03:59:12.625 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-03 03:59:12.634 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-03 03:59:12.637 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>EC[g/l]</th>\n",
       "      <th>station</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>DO Value</th>\n",
       "      <th>DO Temperature</th>\n",
       "      <th>EC Value (us/cm)</th>\n",
       "      <th>EC Temperature</th>\n",
       "      <th>Battery Voltage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1996-02-02 03:00:00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>AnDinh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1996-02-02 05:00:00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>AnDinh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1996-02-02 07:00:00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>AnDinh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1996-02-04 17:00:00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>AnDinh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1996-02-04 19:00:00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>AnDinh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ds  EC[g/l]  ... EC Temperature  Battery Voltage\n",
       "0 1996-02-02 03:00:00      0.1  ...            NaN              NaN\n",
       "1 1996-02-02 05:00:00      0.1  ...            NaN              NaN\n",
       "2 1996-02-02 07:00:00      0.1  ...            NaN              NaN\n",
       "3 1996-02-04 17:00:00      0.1  ...            NaN              NaN\n",
       "4 1996-02-04 19:00:00      0.1  ...            NaN              NaN\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data import combined_data_retrieve\n",
    "\n",
    "df = combined_data_retrieve()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ac6d4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.date(2025, 6, 6), datetime.date(1995, 2, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"ds\"].max().date(), df[\"ds\"].min().date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5609ad79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype: object\n",
      "first rows: ['1996-02-02 03:00:00+07:00', '1996-02-02 05:00:00+07:00', '1996-02-02 07:00:00+07:00', '1996-02-04 17:00:00+07:00', '1996-02-04 19:00:00+07:00', '1996-02-04 21:00:00+07:00', '1996-02-04 23:00:00+07:00', '1996-02-05 05:00:00+07:00', '1996-02-05 07:00:00+07:00', '1996-02-05 09:00:00+07:00']\n",
      "{<class 'str'>: 863428}\n"
     ]
    }
   ],
   "source": [
    "# after reading df\n",
    "print(\"dtype:\", df[\"ds\"].dtype)\n",
    "print(\"first rows:\", df[\"ds\"].head(10).tolist())\n",
    "\n",
    "# count actual Python types inside the Series\n",
    "print(df[\"ds\"].map(type).value_counts().to_dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
